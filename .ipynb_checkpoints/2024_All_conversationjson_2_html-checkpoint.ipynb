{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "def split_and_save_conversations(conversations_file, output_folder):\n",
    "    try:\n",
    "        with open(conversations_file, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "            for conversation in data:\n",
    "                title = conversation.get('title', 'Unknown_Title')\n",
    "                title_with_underscores = title.replace(' ', '_')\n",
    "                chapter_filename = f\"{title_with_underscores}.json\"\n",
    "                chapter_filepath = os.path.join(output_folder, chapter_filename)\n",
    "                \n",
    "                logging.info(f\"Saving data for conversation '{title}' to {chapter_filepath}\")\n",
    "                \n",
    "                with open(chapter_filepath, 'w', encoding='utf-8') as chapter_file:\n",
    "                    json.dump([conversation], chapter_file, indent=2)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {conversations_file}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(f\"Error decoding JSON in file: {conversations_file}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "conversations_file_path = '/home/jack/Documents/CHATDPT/conversations.json'\n",
    "output_folder = '/home/jack/Documents/CHATDPT/chapters_indexed'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Call the split and save function\n",
    "split_and_save_conversations(conversations_file_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77193dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile json2html.py\n",
    "#!/home/jack/miniconda3/envs/cloned_base/bin/python\n",
    "import json\n",
    "from sys import argv\n",
    "# Load the JSON data from the uploaded file\n",
    "DIR=\"/home/jack/Documents/CHATDPT/chapters_indexed/\"\n",
    "filename=argv[1]\n",
    "Filename = DIR+filename\n",
    "print(Filename)\n",
    "with open(Filename, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Initialize the result string\n",
    "result_str = \"\"\n",
    "\n",
    "# Define a function to get conversation messages similar to the JavaScript logic\n",
    "def get_conversation_messages(conversation):\n",
    "    messages = []\n",
    "    current_node = conversation.get('current_node')\n",
    "    while current_node:\n",
    "        node = conversation['mapping'][current_node]\n",
    "        message = node.get('message')\n",
    "        if (message and message.get('content') and message['content'].get('content_type') == 'text' and\n",
    "            len(message['content'].get('parts', [])) > 0 and len(message['content']['parts'][0]) > 0 and\n",
    "                (message['author']['role'] != 'system' or message.get('metadata', {}).get('is_user_system_message'))):\n",
    "            author = message['author']['role']\n",
    "            if author == 'assistant':\n",
    "                author = 'ChatGPT'\n",
    "            elif author == 'system' and message['metadata'].get('is_user_system_message'):\n",
    "                author = 'Custom user info'\n",
    "            messages.append({'author': author, 'text': message['content']['parts'][0]})\n",
    "        current_node = node.get('parent')\n",
    "    return messages[::-1]  # Reverse the list to maintain chronological order\n",
    "\n",
    "# Iterate over each conversation in the JSON data and process it\n",
    "for conversation in json_data:\n",
    "    # Get the conversation title and messages\n",
    "    title = conversation.get('title', '')\n",
    "    messages = get_conversation_messages(conversation)\n",
    "\n",
    "    # Append the title and messages to the result string\n",
    "    result_str += title + '\\n'\n",
    "    for message in messages:\n",
    "        result_str += message['author'] + '\\n' + message['text'] + '\\n'\n",
    "    result_str += '\\n'  # Add a newline between conversations\n",
    "\n",
    "# Return the processed result string\n",
    "print(result_str.strip())\n",
    "HTMLfile=DIR+filename[:-4]+\"html\"\n",
    "print(\"HTMLfile: \",HTMLfile)\n",
    "Input = open(HTMLfile,\"w\")\n",
    "result_str = result_str.replace(\"/n\",\"XXXXXXX\\n\")\n",
    "result_str = result_str.replace(\"<\",\"&lt;\")\n",
    "result_str = result_str.replace(\">\",\"&gt;\")\n",
    "for line in result_str.split(\"XXXXXXX\"):\n",
    "    line = line.replace(\"\\n\",\"<br />\\n\")\n",
    "    Input.write(line)\n",
    "Input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8dc83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x json2html.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/jack/miniconda3/envs/cloned_base/bin/python\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import logging\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(filename='conversion_log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the directory path\n",
    "DIR = \"/home/jack/Documents/CHATDPT/chapters_indexed/\"\n",
    "\n",
    "# List all JSON files in the directory\n",
    "jsonfiles = glob.glob(DIR + '*.json')\n",
    "\n",
    "if not jsonfiles:\n",
    "    logging.warning(\"No JSON files found in the specified directory.\")\n",
    "    exit()\n",
    "\n",
    "# Iterate over each JSON file in the directory\n",
    "for json_file in jsonfiles:\n",
    "    # Load the JSON data from the current file\n",
    "    with open(json_file, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    # Initialize the result string\n",
    "    result_str = \"\"\n",
    "\n",
    "    # Rest of the script remains unchanged...\n",
    "    # (Omitted for brevity, you can keep the rest of your script as is)\n",
    "\n",
    "    # Process the current JSON file\n",
    "    for conversation in json_data:\n",
    "        title = conversation.get('title', '')\n",
    "        messages = get_conversation_messages(conversation)\n",
    "        result_str += title + '\\n'\n",
    "        for message in messages:\n",
    "            result_str += message['author'] + '\\n' + message['text'] + '\\n'\n",
    "        result_str += '\\n'\n",
    "\n",
    "    # Define the HTML file path based on the current JSON file\n",
    "    HTMLfile = os.path.join(DIR, os.path.basename(json_file)[:-5] + \".html\")\n",
    "\n",
    "    print(\"HTMLfile: \", HTMLfile)\n",
    "\n",
    "    # Write the HTML content to the file\n",
    "    with open(HTMLfile, \"w\") as Input:\n",
    "        result_str = result_str.replace(\"\\n\", \"XXXXXXX\\n\")\n",
    "        result_str = result_str.replace(\"<\", \"&lt;\")\n",
    "        result_str = result_str.replace(\">\", \"&gt;\")\n",
    "        for line in result_str.split(\"XXXXXXX\"):\n",
    "            line = line.replace(\"\\n\", \"<br />\\n\")\n",
    "            Input.write(line)\n",
    "\n",
    "    print(f\"HTML conversion completed for {json_file}.\")\n",
    "\n",
    "# Logging for the entire process completion\n",
    "logging.info(\"Conversion process completed for all JSON files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df6ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import uuid\n",
    "\n",
    "# Connect to SQLite database\n",
    "db_path = 'chat_database.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def retrieve_file_content(filename):\n",
    "    cursor.execute('SELECT content FROM files WHERE filename = ?', (filename,))\n",
    "    result = cursor.fetchone()\n",
    "    return result[0] if result else None\n",
    "\n",
    "def search_and_print_fourth_file(search_terms):\n",
    "    Data = \"\"\n",
    "\n",
    "    # Prepare the SQL query for searching files based on the given terms\n",
    "    query = '''\n",
    "        SELECT filename\n",
    "        FROM files\n",
    "        WHERE {}\n",
    "    '''.format(' AND '.join(['text_content LIKE ?' for _ in search_terms]))\n",
    "\n",
    "    # Add % around search terms for a partial match with spaces\n",
    "    search_terms = ['% {} %'.format(term) for term in search_terms]\n",
    "\n",
    "    # Execute the query and retrieve matching files\n",
    "    cursor.execute(query, search_terms)\n",
    "    matching_files = cursor.fetchall()\n",
    "\n",
    "    # Check if there are at least 2 matching files\n",
    "    if matching_files and len(matching_files) >= 2:\n",
    "        fourth_file = matching_files[1][0]  # Get the filename of the second matching file\n",
    "        print(fourth_file)\n",
    "\n",
    "        # Retrieve the content of the matching file\n",
    "        content = retrieve_file_content(fourth_file)\n",
    "        \n",
    "        if content:\n",
    "            # Decode the content and append it to the Data variable\n",
    "            Data = Data + f'{content.decode(\"utf-8\", errors=\"ignore\")}'\n",
    "            print(Data)\n",
    "            return Data\n",
    "        else:\n",
    "            print(f'Error: Content not found for {fourth_file}')\n",
    "    else:\n",
    "        print('Error: No matching files found or less than two matching files.')\n",
    "\n",
    "# Example: Search for files containing 'flask' and '5200'\n",
    "search_terms = ['flask', '5200']\n",
    "DATA = search_and_print_fourth_file(search_terms)\n",
    "\n",
    "# Close the connection to the database\n",
    "conn.close()\n",
    "\n",
    "# If data is found, create a unique filename and write the content to an HTML file\n",
    "if len(DATA) > 2:\n",
    "    uid = str(uuid.uuid4())  # Generate a unique ID using uuid\n",
    "    FileName = \"_\".join(search_terms) + \"_\" + uid + \".html\"\n",
    "    print(FileName)\n",
    "\n",
    "    # Open the file for writing\n",
    "    with open(FileName, \"w\") as IN:\n",
    "        # Split the data into lines and write each line to the file with \"<br />\" appended\n",
    "        ndata = DATA.split(\"<br />\\n\")\n",
    "        for line in ndata:\n",
    "            print(line)\n",
    "            IN.write(line + \"<br />\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189615e",
   "metadata": {},
   "source": [
    "## Explanation and Comments:\n",
    "\n",
    "### Database Connection:\n",
    "- Establishes a connection to the SQLite database.\n",
    "\n",
    "### Function `retrieve_file_content`:\n",
    "- Retrieves the content of a file from the database based on the filename.\n",
    "\n",
    "### Function `search_and_print_fourth_file`:\n",
    "- Searches for files based on given search terms using SQL LIKE.\n",
    "- Retrieves the second matching file (index 1) and its content.\n",
    "- Appends the decoded content to the `Data` variable.\n",
    "\n",
    "### Example Search:\n",
    "- Searches for files containing 'flask' and '5200'.\n",
    "\n",
    "### Close Connection:\n",
    "- Closes the connection to the database.\n",
    "\n",
    "### Create Unique Filename and Write HTML File:\n",
    "- If data is found, generates a unique filename with search terms and a UUID.\n",
    "- Opens the file for writing and writes each line of the content with \"<br />\" appended.\n",
    "\n",
    "This script is designed to search for files based on certain terms, retrieve the content of the second matching file, and then create an HTML file with a unique filename and the retrieved content. Feel free to ask if you have any specific questions or if there's anything else you'd like to understand!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02e50a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloned-base",
   "language": "python",
   "name": "cloned-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
